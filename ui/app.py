"""Streamlit UI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""

import streamlit as st
import numpy as np
import cv2
from typing import Optional, Dict, List, Tuple, Any
import tempfile
import os
import io
import matplotlib.pyplot as plt

from pose.mediapipe_pose import initialize_pose, process_frame
from analysis.angles import (
    calculate_elbow_angle,
    calculate_all_angles_from_landmarks,
)
from analysis.velocity import calculate_wrist_velocity, calculate_angular_velocity
from analysis.phases import detect_pitching_phases, calculate_phase_summary
from analysis.metrics import compute_pitching_metrics
from analysis.evaluator import evaluate_pitching_form
from utils.debug_draw import draw_landmarks_on_frame, draw_trail_skeleton

# ãƒšãƒ¼ã‚¸è¨­å®šï¼šãƒ¯ã‚¤ãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
st.set_page_config(layout="wide")

# CSS: ã‚³ãƒ³ãƒ†ãƒŠå¹…ã‚’100%ã«
st.markdown(
    """
    <style>
    .block-container {
        max-width: 100% !important;
        padding-left: 2rem;
        padding-right: 2rem;
    }
    </style>
    """,
    unsafe_allow_html=True
)


def _save_uploaded_file_to_temp(uploaded_file: Any) -> Optional[str]:
    """
    Cloud Run å¯¾å¿œ: /tmp ãƒ•ã‚©ãƒ«ãƒ€ã«ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    
    Args:
        uploaded_file: Streamlitã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    
    Returns:
        ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
    """
    if uploaded_file is None:
        st.error("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return None

    try:
        # read() ã§ä¸€åº¦ã ã‘ãƒã‚¤ãƒˆåˆ—å–å¾—
        if hasattr(uploaded_file, 'seek'):
            uploaded_file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
        file_bytes = uploaded_file.read()
        if not file_bytes:
            st.error("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå‹•ç”»ãŒç©ºã§ã™")
            return None

        # /tmp ãƒ•ã‚©ãƒ«ãƒ€ã«æ˜ç¤ºçš„ã«ä¿å­˜ï¼ˆCloud Run å¯¾å¿œï¼‰
        tmp_dir = "/tmp"
        os.makedirs(tmp_dir, exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’å–å¾—
        if hasattr(uploaded_file, 'name') and uploaded_file.name:
            file_ext = os.path.splitext(uploaded_file.name)[1] or ".mp4"
        else:
            file_ext = ".mp4"
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ
        tmp_file_path = tempfile.mktemp(suffix=file_ext, dir=tmp_dir)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with open(tmp_file_path, "wb") as tmp_file:
            tmp_file.write(file_bytes)
        
        return tmp_file_path

    except Exception as e:
        st.error(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        return None


def _read_frames_from_video(
    video_path: str,
    max_frames: int = 1000,
    max_width: int = 1280,
    frame_skip: int = 1,
    progress_container: Any = None
) -> Optional[List[np.ndarray]]:
    """å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿è¾¼ã‚€ï¼ˆCloud Run å¯¾å¿œï¼šå¤§ããªå‹•ç”»ã§ã‚‚ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãªã„ï¼‰
    
    Args:
        video_path: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        max_frames: æœ€å¤§ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
        max_width: æœ€å¤§å¹…ï¼ˆãƒªã‚µã‚¤ã‚ºï¼‰
        frame_skip: ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æ•°ï¼ˆ1=å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã€2=1ãƒ•ãƒ¬ãƒ¼ãƒ ãŠãï¼‰
        progress_container: é€²è¡ŒçŠ¶æ³è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
    
    Returns:
        ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒªã‚¹ãƒˆï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
    """
    cap = cv2.VideoCapture(video_path)
    frames: List[np.ndarray] = []
    
    if not cap.isOpened():
        if progress_container:
            progress_container.error("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
        return None
    
    try:
        # å‹•ç”»æƒ…å ±ã‚’å–å¾—
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        if progress_container:
            progress_container.info(f"å‹•ç”»æƒ…å ±: {width}x{height}, {total_frames}ãƒ•ãƒ¬ãƒ¼ãƒ , {fps:.1f}fps")
        
        # ãƒªã‚µã‚¤ã‚ºãŒå¿…è¦ã‹åˆ¤å®š
        resize_needed = width > max_width
        if resize_needed:
            scale = max_width / width
            new_width = max_width
            new_height = int(height * scale)
            if progress_container:
                progress_container.info(f"å‹•ç”»ã‚’ãƒªã‚µã‚¤ã‚º: {new_width}x{new_height}")
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã‚’èª¿æ•´ï¼ˆå‹•ç”»ãŒé•·ã™ãã‚‹å ´åˆï¼‰
        if total_frames > max_frames * frame_skip:
            frame_skip = max(1, total_frames // max_frames)
            if progress_container:
                progress_container.info(f"ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—: {frame_skip}ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ã®ãŸã‚ï¼‰")
        
        frame_count = 0
        read_count = 0
        
        progress_bar = None
        if progress_container:
            progress_bar = progress_container.progress(0)
            status_text = progress_container.empty()
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—
            if frame_count % frame_skip != 0:
                frame_count += 1
                continue
            
            # ãƒªã‚µã‚¤ã‚º
            if resize_needed:
                frame = cv2.resize(frame, (new_width, new_height))
            
            frames.append(frame)
            read_count += 1
            
            # é€²è¡ŒçŠ¶æ³æ›´æ–°
            if progress_bar and frame_count % 10 == 0:
                progress = min(1.0, frame_count / total_frames)
                progress_bar.progress(progress)
                if status_text:
                    status_text.text(f"èª­ã¿è¾¼ã¿ä¸­: {read_count}/{min(total_frames // frame_skip, max_frames)} ãƒ•ãƒ¬ãƒ¼ãƒ ")
            
            # æœ€å¤§ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã«é”ã—ãŸã‚‰çµ‚äº†
            if read_count >= max_frames:
                if progress_container:
                    progress_container.warning(f"æœ€å¤§ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆ{max_frames}ï¼‰ã«é”ã—ãŸãŸã‚ã€èª­ã¿è¾¼ã¿ã‚’çµ‚äº†ã—ã¾ã—ãŸ")
                break
            
            frame_count += 1
        
        if progress_bar:
            progress_bar.progress(1.0)
        if progress_container:
            progress_container.success(f"âœ… {read_count} ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        
        return frames if frames else None
    
    finally:
        cap.release()


def load_video_frames(
    uploaded_file: Any,
    progress_container: Any = None
) -> Optional[List[np.ndarray]]:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿è¾¼ã‚€ï¼ˆCloud Run å¯¾å¿œï¼‰
    
    Args:
        uploaded_file: Streamlitã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        progress_container: é€²è¡ŒçŠ¶æ³è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
    
    Returns:
        ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒªã‚¹ãƒˆï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
    """
    if uploaded_file is None:
        return None
    
    tmp_path = _save_uploaded_file_to_temp(uploaded_file)
    if tmp_path is None:
        return None
    
    try:
        return _read_frames_from_video(tmp_path, progress_container=progress_container)
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆCloud Run ã§ã¯ /tmp ã¯è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚Œã‚‹ãŒã€æ˜ç¤ºçš„ã«å‰Šé™¤ï¼‰
        try:
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
        except Exception:
            pass  # å‰Šé™¤å¤±æ•—ã¯ç„¡è¦–


def process_video_frames(
    frames: List[np.ndarray],
    progress_container: Any = None
) -> List[Optional[Dict[str, Dict[str, float]]]]:
    """å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã—ã¦ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’å–å¾—ï¼ˆCloud Run å¯¾å¿œï¼šé€²è¡ŒçŠ¶æ³è¡¨ç¤ºï¼‰
    
    Args:
        frames: ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒªã‚¹ãƒˆ
        progress_container: é€²è¡ŒçŠ¶æ³è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
    
    Returns:
        å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¾æ›¸ã®ãƒªã‚¹ãƒˆ
    """
    pose = initialize_pose()
    results = []
    total_frames = len(frames)
    
    progress_bar = None
    status_text = None
    if progress_container:
        progress_bar = progress_container.progress(0)
        status_text = progress_container.empty()
    
    for idx, frame in enumerate(frames):
        landmarks = process_frame(pose, frame)
        results.append(landmarks)
        
        # é€²è¡ŒçŠ¶æ³æ›´æ–°ï¼ˆ10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ï¼‰
        if progress_bar and idx % 10 == 0:
            progress = (idx + 1) / total_frames
            progress_bar.progress(progress)
            if status_text:
                status_text.text(f"å§¿å‹¢æ¨å®šä¸­: {idx + 1}/{total_frames} ãƒ•ãƒ¬ãƒ¼ãƒ ")
    
    if progress_bar:
        progress_bar.progress(1.0)
    if status_text:
        status_text.text(f"âœ… {total_frames} ãƒ•ãƒ¬ãƒ¼ãƒ ã®å§¿å‹¢æ¨å®šãŒå®Œäº†ã—ã¾ã—ãŸ")
    
    return results


def _extract_landmark_coordinates(
    landmarks: Dict[str, Dict[str, float]],
    landmark_name: str
) -> Optional[np.ndarray]:
    """ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¾æ›¸ã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®åº§æ¨™ã‚’æŠ½å‡ºã™ã‚‹
    
    Args:
        landmarks: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¾æ›¸
        landmark_name: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å
    
    Returns:
        åº§æ¨™é…åˆ— (x, y, z)ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯Noneï¼‰
    """
    if landmark_name not in landmarks:
        return None
    
    landmark = landmarks[landmark_name]
    return np.array([landmark["x"], landmark["y"], landmark["z"]])


def _calculate_single_elbow_angle(
    landmarks: Optional[Dict[str, Dict[str, float]]]
) -> Optional[float]:
    """1ãƒ•ãƒ¬ãƒ¼ãƒ ã®å³è‚˜ã®è§’åº¦ã‚’è¨ˆç®—ã™ã‚‹
    
    Args:
        landmarks: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¾æ›¸
    
    Returns:
        å³è‚˜ã®è§’åº¦ï¼ˆåº¦ï¼‰ï¼ˆè¨ˆç®—ã§ããªã„å ´åˆã¯Noneï¼‰
    """
    if landmarks is None:
        return None
    
    shoulder = _extract_landmark_coordinates(landmarks, "right_shoulder")
    elbow = _extract_landmark_coordinates(landmarks, "right_elbow")
    wrist = _extract_landmark_coordinates(landmarks, "right_wrist")
    
    if shoulder is None or elbow is None or wrist is None:
        return None
    
    return calculate_elbow_angle(shoulder, elbow, wrist)


def calculate_elbow_angles_from_landmarks(
    landmarks_list: List[Optional[Dict[str, Dict[str, float]]]]
) -> List[Optional[float]]:
    """ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‹ã‚‰è‚˜ã®è§’åº¦ã‚’è¨ˆç®—
    
    Args:
        landmarks_list: å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¾æ›¸ã®ãƒªã‚¹ãƒˆ
    
    Returns:
        å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®è‚˜ã®è§’åº¦ã®ãƒªã‚¹ãƒˆ
    """
    return [_calculate_single_elbow_angle(landmarks) for landmarks in landmarks_list]


def _render_video_upload() -> Optional[Any]:
    """å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰UIã‚’è¡¨ç¤ºã™ã‚‹
    
    Returns:
        ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    return st.file_uploader(
        "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=["mp4", "avi", "mov", "mkv"]
    )


def _render_video_preview(uploaded_file: Any) -> None:
    """å‹•ç”»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹
    
    Args:
        uploaded_file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    st.subheader("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå‹•ç”»")
    st.video(uploaded_file)


def _render_frame_viewer(
    frames: List[np.ndarray],
    frame_idx: int,
    landmarks: Optional[Dict[str, Dict[str, float]]],
    elbow_angle: Optional[float],
    torso_angle: Optional[float] = None,
    shoulder_line_angle: Optional[float] = None,
    hip_line_angle: Optional[float] = None,
) -> None:
    """ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹
    
    Args:
        frames: ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒªã‚¹ãƒˆ
        frame_idx: è¡¨ç¤ºã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        landmarks: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¾æ›¸
        elbow_angle: è‚˜ã®è§’åº¦
    """
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ")
        frame_copy = frames[frame_idx].copy()
        if landmarks is not None:
            frame_with_skeleton = draw_landmarks_on_frame(frame_copy, landmarks)
        else:
            frame_with_skeleton = frame_copy
        frame_rgb = cv2.cvtColor(frame_with_skeleton, cv2.COLOR_BGR2RGB)
        st.image(frame_rgb, use_container_width=True)
    
    with col2:
        st.write("è§£ææƒ…å ±")
        if landmarks is not None:
            st.success("å§¿å‹¢æ¤œå‡º: æˆåŠŸ")
            cols = st.columns(2)
            with cols[0]:
                if elbow_angle is not None:
                    st.metric("å³è‚˜ã®è§’åº¦", f"{elbow_angle:.1f}Â°")
                else:
                    st.metric("å³è‚˜ã®è§’åº¦", "N/A")
                if torso_angle is not None:
                    st.metric("ä½“å¹¹å‚¾ã", f"{torso_angle:.1f}Â°")
                else:
                    st.metric("ä½“å¹¹å‚¾ã", "N/A")
            with cols[1]:
                if shoulder_line_angle is not None:
                    st.metric("è‚©ãƒ©ã‚¤ãƒ³è§’åº¦", f"{shoulder_line_angle:.1f}Â°")
                else:
                    st.metric("è‚©ãƒ©ã‚¤ãƒ³è§’åº¦", "N/A")
                if hip_line_angle is not None:
                    st.metric("éª¨ç›¤è§’åº¦", f"{hip_line_angle:.1f}Â°")
                else:
                    st.metric("éª¨ç›¤è§’åº¦", "N/A")
        else:
            st.error("å§¿å‹¢æ¤œå‡º: å¤±æ•—")


def create_annotated_video(
    frames: List[np.ndarray],
    landmarks_list: List[Optional[Dict[str, Dict[str, float]]]],
    background_color: Optional[str] = None,
    trail_mode: bool = False,
    max_trail_history: int = 5,
    trail_decay: float = 0.92,
) -> Optional[str]:
    """éª¨æ ¼æç”»æ¸ˆã¿ã®è§£æå‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹
    
    Args:
        frames: ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒªã‚¹ãƒˆ
        landmarks_list: å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¾æ›¸ã®ãƒªã‚¹ãƒˆ
        background_color: èƒŒæ™¯è‰² ('white', 'black', None=å…ƒå‹•ç”»)
        trail_mode: æ®‹åƒãƒˆãƒ¬ã‚¤ãƒ«ãƒ¢ãƒ¼ãƒ‰ï¼ˆTrue: æ®‹åƒè¡¨ç¤º, False: é€šå¸¸ï¼‰
        max_trail_history: æ®‹åƒã¨ã—ã¦è¡¨ç¤ºã™ã‚‹æœ€å¤§ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
    """
    if not frames or not landmarks_list:
        st.warning("ãƒ•ãƒ¬ãƒ¼ãƒ ã¾ãŸã¯ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãŒç©ºã§ã™")
        return None
    
    # Cloud Run å¯¾å¿œ: /tmp ãƒ•ã‚©ãƒ«ãƒ€ã«ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    tmp_dir = "/tmp"
    os.makedirs(tmp_dir, exist_ok=True)
    output_path = tempfile.mktemp(suffix='.mp4', dir=tmp_dir)
    
    # å‹•ç”»ã®ã‚µã‚¤ã‚ºã¨FPSã‚’å–å¾—ï¼ˆæœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ï¼‰
    if len(frames[0].shape) < 2:
        st.error("ãƒ•ãƒ¬ãƒ¼ãƒ ã®å½¢çŠ¶ãŒä¸æ­£ã§ã™")
        return None
    
    # frames[0].shape[:2] ã®é †åºã¯ (height, width) ã§æ­£ã—ã„
    height, width = frames[0].shape[:2]
    
    # å‹•ç”»ã‚µã‚¤ã‚ºã®å¦¥å½“æ€§ç¢ºèª
    if width <= 0 or height <= 0:
        st.error(f"å‹•ç”»ã‚µã‚¤ã‚ºãŒä¸æ­£ã§ã™: {width}x{height}")
        return None
    
    fps = 30.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆFPS
    
    # Cloud Run å¯¾å¿œ: è¤‡æ•°ã®ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ã‚’é †ç•ªã«è©¦ã™
    # å„ªå…ˆé †ä½: avc1 (H.264) â†’ mp4v (MPEG-4 Part 2) â†’ XVID
    codecs_to_try = [
        ('avc1', 'H.264 (avc1)'),
        ('mp4v', 'MPEG-4 Part 2 (mp4v)'),
        ('XVID', 'XVID'),
    ]
    
    out = None
    used_codec = None
    for codec_name, codec_desc in codecs_to_try:
        fourcc = cv2.VideoWriter_fourcc(*codec_name)
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        if out.isOpened():
            used_codec = codec_desc
            break
        else:
            if out is not None:
                out.release()
            out = None
    
    if out is None or not out.isOpened():
        st.error("åˆ©ç”¨å¯èƒ½ãªå‹•ç”»ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ffmpegå…¥ã‚ŠOpenCVãŒå¿…è¦ã§ã™")
        return None
    
    # ä½¿ç”¨ã—ãŸã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    if used_codec:
        st.info(f"å‹•ç”»ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯: {used_codec}")
    
    written_frames = 0
    skipped_frames = 0
    history_landmarks: List[Optional[Dict[str, Dict[str, float]]]] = []
    
    try:
        for idx, (frame, landmarks) in enumerate(zip(frames, landmarks_list)):
            # ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç©ºã®ã¨ãã¯ã‚¹ã‚­ãƒƒãƒ—
            if frame is None or frame.size == 0:
                skipped_frames += 1
                st.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {idx} ãŒç©ºã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
                continue
            
            # èƒŒæ™¯è‰²ã«å¿œã˜ã¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æº–å‚™
            if background_color == 'white':
                # ç™½èƒŒæ™¯
                frame_copy = np.ones((height, width, 3), dtype=np.uint8) * 255
            elif background_color == 'black':
                # é»’èƒŒæ™¯
                frame_copy = np.zeros((height, width, 3), dtype=np.uint8)
            else:
                # å…ƒå‹•ç”»ã‚’ä½¿ç”¨
                frame_copy = frame.copy()
            
            # æ®‹åƒãƒˆãƒ¬ã‚¤ãƒ«ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
            if trail_mode and landmarks is not None:
                # å±¥æ­´ã«ç¾åœ¨ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’è¿½åŠ 
                history_landmarks.insert(0, landmarks)
                # æœ€å¤§å±¥æ­´æ•°ã‚’è¶…ãˆãŸã‚‰å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
                if len(history_landmarks) > max_trail_history:
                    history_landmarks.pop()
                
                # æ®‹åƒéª¨æ ¼ã‚’æç”»
                frame_with_skeleton = draw_trail_skeleton(
                    frame_copy,
                    history_landmarks,
                    max_trail_history,
                    decay_base=trail_decay,
                )
            elif landmarks is not None:
                # é€šå¸¸ã®éª¨æ ¼æç”»
                frame_with_skeleton = draw_landmarks_on_frame(frame_copy, landmarks)
            else:
                frame_with_skeleton = frame_copy
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ BGR 3ãƒãƒ£ãƒ³ãƒãƒ«ã«å¤‰æ›
            if len(frame_with_skeleton.shape) == 2:
                # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ« (1ãƒãƒ£ãƒ³ãƒãƒ«) â†’ BGR
                frame_with_skeleton = cv2.cvtColor(frame_with_skeleton, cv2.COLOR_GRAY2BGR)
            elif len(frame_with_skeleton.shape) == 3:
                if frame_with_skeleton.shape[2] == 4:
                    # BGRA (4ãƒãƒ£ãƒ³ãƒãƒ«) â†’ BGR
                    frame_with_skeleton = cv2.cvtColor(frame_with_skeleton, cv2.COLOR_BGRA2BGR)
                elif frame_with_skeleton.shape[2] == 1:
                    # 1ãƒãƒ£ãƒ³ãƒãƒ« â†’ BGR
                    frame_with_skeleton = cv2.cvtColor(frame_with_skeleton, cv2.COLOR_GRAY2BGR)
                elif frame_with_skeleton.shape[2] != 3:
                    st.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {idx}: äºˆæœŸã—ãªã„ãƒãƒ£ãƒ³ãƒãƒ«æ•° ({frame_with_skeleton.shape[2]})")
                    continue
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºãŒä¸€è‡´ã™ã‚‹ã‹ç¢ºèª
            if frame_with_skeleton.shape[:2] != (height, width):
                st.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {idx}: ã‚µã‚¤ã‚ºä¸ä¸€è‡´ ({frame_with_skeleton.shape[:2]} vs ({height}, {width}))")
                # ãƒªã‚µã‚¤ã‚º
                frame_with_skeleton = cv2.resize(frame_with_skeleton, (width, height))
            
            out.write(frame_with_skeleton)
            written_frames += 1
            
    finally:
        out.release()
    
    # æ›¸ãè¾¼ã¿å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª
    if os.path.exists(output_path):
        file_size = os.path.getsize(output_path)
        st.info(f"å‹•ç”»ç”Ÿæˆå®Œäº†: {output_path}, ã‚µã‚¤ã‚º: {file_size / (1024*1024):.2f} MB, æ›¸ãè¾¼ã¿ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {written_frames}, ã‚¹ã‚­ãƒƒãƒ—: {skipped_frames}")
        
        if file_size == 0:
            st.error("ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒ0ãƒã‚¤ãƒˆã§ã™")
            return None
    else:
        st.error(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {output_path}")
        return None
    
    return output_path


def _render_angle_chart(elbow_angles: List[Optional[float]]) -> None:
    """è§’åº¦ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹
    
    Args:
        elbow_angles: å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®è‚˜ã®è§’åº¦ã®ãƒªã‚¹ãƒˆ
    """
    if not any(angle is not None for angle in elbow_angles):
        return
    
    st.subheader("å³è‚˜ã®è§’åº¦å¤‰åŒ–")
    
    fig, ax = plt.subplots()
    valid_angles = [angle if angle is not None else 0.0 for angle in elbow_angles]
    ax.plot(valid_angles)
    ax.set_xlabel("ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·")
    ax.set_ylabel("è§’åº¦ï¼ˆåº¦ï¼‰")
    ax.set_title("å³è‚˜ã®è§’åº¦å¤‰åŒ–")
    ax.grid(True)
    st.pyplot(fig)


def _render_multi_analysis_charts(
    analysis_data: Dict[str, List[Optional[float]]],
    selected_analyses: List[str]
) -> None:
    """è¤‡æ•°ã®è§£æçµæœã‚’ã‚°ãƒ©ãƒ•è¡¨ç¤ºã™ã‚‹
    
    Args:
        analysis_data: è§£æãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
        selected_analyses: è¡¨ç¤ºã™ã‚‹è§£æç¨®é¡ã®ãƒªã‚¹ãƒˆ
    """
    if not selected_analyses:
        return
    
    st.subheader("è§£æçµæœã‚°ãƒ©ãƒ•")
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    for analysis_name in selected_analyses:
        if analysis_name not in analysis_data:
            continue
        
        values = analysis_data[analysis_name]
        valid_values = [v if v is not None else 0.0 for v in values]
        
        ax.plot(valid_values, label=analysis_name, alpha=0.7)
    
    ax.set_xlabel("ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·")
    ax.set_ylabel("å€¤")
    ax.set_title("è§£æçµæœã®æ™‚é–“å¤‰åŒ–")
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)


def _render_phase_summary(phase_summary: Dict[str, Dict[str, float]]) -> None:
    """æŠ•çƒãƒ•ã‚§ãƒ¼ã‚ºã”ã¨ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹
    
    Args:
        phase_summary: ãƒ•ã‚§ãƒ¼ã‚ºã”ã¨ã®ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿
    """
    if not phase_summary:
        return
    
    st.subheader("æŠ•çƒãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ã‚µãƒãƒªãƒ¼")
    
    for phase_name, phase_data in phase_summary.items():
        with st.expander(f"ğŸ“Š {phase_name}", expanded=False):
            if phase_data:
                cols = st.columns(min(3, len(phase_data)))
                for idx, (key, value) in enumerate(phase_data.items()):
                    with cols[idx % len(cols)]:
                        st.metric(key.replace("_", " ").title(), f"{value:.2f}")
            else:
                st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")


def _render_video_list_panel() -> None:
    """å·¦å´ãƒ‘ãƒãƒ«ï¼šè§£ææ¸ˆã¿å‹•ç”»ãƒªã‚¹ãƒˆã¨ã‚µãƒ ãƒã‚¤ãƒ«è¡¨ç¤º"""
    st.subheader("ğŸ“ è§£ææ¸ˆã¿å‹•ç”»")
    
    video_list = st.session_state.get("video_list", [])
    
    if not video_list:
        st.info("ğŸ“¤ å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„")
        return
    
    # å‹•ç”»ãƒªã‚¹ãƒˆã‚’è¡¨ç¤º
    for idx, video_data in enumerate(video_list):
        # ã‚«ãƒ¼ãƒ‰é¢¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
        with st.container():
            # é¸æŠçŠ¶æ…‹ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            is_selected = idx == st.session_state.get("selected_video_index", 0)
            border_color = "#1f77b4" if is_selected else "#e0e0e0"
            
            st.markdown(
                f"""
                <div style="border: 2px solid {border_color}; border-radius: 8px; padding: 10px; margin-bottom: 10px; 
                            background-color: {'#f0f8ff' if is_selected else '#ffffff'};">
                """,
                unsafe_allow_html=True
            )
            
            # å‹•ç”»å
            st.markdown(f"**{idx + 1}. {video_data.get('name', f'å‹•ç”» {idx + 1}')}**")
            
            # ã‚µãƒ ãƒã‚¤ãƒ«è¡¨ç¤º
            frames = video_data.get("frames", [])
            if frames and len(frames) > 0:
                # æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚µãƒ ãƒã‚¤ãƒ«ã¨ã—ã¦ä½¿ç”¨
                thumb_frame = frames[0].copy()
                thumb_rgb = cv2.cvtColor(thumb_frame, cv2.COLOR_BGR2RGB)
                st.image(thumb_rgb, use_container_width=True, caption="ã‚µãƒ ãƒã‚¤ãƒ«")
            
            # é¸æŠãƒœã‚¿ãƒ³
            if st.button(f"é¸æŠ", key=f"select_video_{idx}", use_container_width=True):
                st.session_state["selected_video_index"] = idx
                st.rerun()
            
            st.markdown("</div>", unsafe_allow_html=True)
    
    # çµ±è¨ˆæƒ…å ±
    st.markdown("---")
    st.markdown(f"**åˆè¨ˆ: {len(video_list)} å‹•ç”»**")


def _render_analysis_tab(
    frames: List[np.ndarray],
    landmarks_list: List[Optional[Dict[str, Dict[str, float]]]],
    elbow_angles: List[Optional[float]]
) -> None:
    """è§£æçµæœã‚¿ãƒ–ï¼šãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼"""
    # è§£æç¨®é¡é¸æŠ
    analysis_types = {
        "è‚˜è§’åº¦": "right_elbow",
        "è‚©è§’åº¦": "right_shoulder",
        "è†è§’åº¦": "right_knee",
        "è…°è§’åº¦": "right_hip",
        "ä½“å¹¹å‚¾ã": "torso_axis",
        "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦": "shoulder_line",
        "éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦": "hip_line",
        "æ‰‹é¦–é€Ÿåº¦": "wrist_velocity",
        "æŠ•çƒãƒ•ã‚§ãƒ¼ã‚º": "pitching_phases",
    }
    
    selected_analysis_names = st.multiselect(
        "ğŸ“Š è§£æç¨®é¡ã‚’é¸æŠ",
        options=list(analysis_types.keys()),
        default=["è‚˜è§’åº¦", "ä½“å¹¹å‚¾ã"],
        key="analysis_type_select_tab"
    )
    
    # è§£æãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—
    analysis_data = {}
    phases = None
    phase_summary = None
    
    # å„ç¨®è§’åº¦ã‚’è¨ˆç®—
    if any(name in ["è‚˜è§’åº¦", "è‚©è§’åº¦", "è†è§’åº¦", "è…°è§’åº¦", "ä½“å¹¹å‚¾ã", "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦", "éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦"] for name in selected_analysis_names):
        all_angles = calculate_all_angles_from_landmarks(landmarks_list)
        angle_mapping = {
            "è‚˜è§’åº¦": "right_elbow",
            "è‚©è§’åº¦": "right_shoulder",
            "è†è§’åº¦": "right_knee",
            "è…°è§’åº¦": "right_hip",
            "ä½“å¹¹å‚¾ã": "torso_axis",
            "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦": "shoulder_line",
            "éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦": "hip_line",
        }
        for name, key in angle_mapping.items():
            if name in selected_analysis_names:
                analysis_data[name] = all_angles[key]
    
    # æ‰‹é¦–é€Ÿåº¦ã‚’è¨ˆç®—
    if "æ‰‹é¦–é€Ÿåº¦" in selected_analysis_names:
        wrist_velocities = calculate_wrist_velocity(landmarks_list)
        analysis_data["æ‰‹é¦–é€Ÿåº¦"] = wrist_velocities
    
    # æŠ•çƒãƒ•ã‚§ãƒ¼ã‚ºã‚’æ¨å®š
    if "æŠ•çƒãƒ•ã‚§ãƒ¼ã‚º" in selected_analysis_names:
        wrist_velocities = calculate_wrist_velocity(landmarks_list)
        phases = detect_pitching_phases(landmarks_list, elbow_angles, wrist_velocities)
        if phases:
            all_angles = calculate_all_angles_from_landmarks(landmarks_list)
            phase_summary = calculate_phase_summary(phases, all_angles, wrist_velocities)
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ é¸æŠ
    frame_idx = st.slider(
        "ğŸ¬ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é¸æŠ",
        min_value=0,
        max_value=len(frames) - 1,
        value=0,
        key="frame_slider_tab"
    )
    
    # ç¾åœ¨ãƒ•ãƒ¬ãƒ¼ãƒ ã®è§’åº¦ã‚’å–å¾—
    torso_angle_val = None
    shoulder_line_angle_val = None
    hip_line_val = None
    
    if "ä½“å¹¹å‚¾ã" in selected_analysis_names and "torso_axis" in analysis_data:
        torso_angle_val = analysis_data["ä½“å¹¹å‚¾ã"][frame_idx] if frame_idx < len(analysis_data["ä½“å¹¹å‚¾ã"]) else None
    
    if "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦" in selected_analysis_names and "shoulder_line" in analysis_data:
        shoulder_line_angle_val = analysis_data["è‚©ãƒ©ã‚¤ãƒ³è§’åº¦"][frame_idx] if frame_idx < len(analysis_data["è‚©ãƒ©ã‚¤ãƒ³è§’åº¦"]) else None
    
    if "éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦" in selected_analysis_names and "hip_line" in analysis_data:
        hip_line_val = analysis_data["éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦"][frame_idx] if frame_idx < len(analysis_data["éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦"]) else None
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼è¡¨ç¤º
    _render_frame_viewer(
        frames,
        frame_idx,
        landmarks_list[frame_idx],
        elbow_angles[frame_idx] if "è‚˜è§’åº¦" in selected_analysis_names else None,
        torso_angle=torso_angle_val,
        shoulder_line_angle=shoulder_line_angle_val,
        hip_line_angle=hip_line_val,
    )
    
    # æŠ•çƒãƒ•ã‚§ãƒ¼ã‚ºã‚µãƒãƒªãƒ¼è¡¨ç¤º
    if phase_summary:
        _render_phase_summary(phase_summary)


def _render_graph_tab(
    frames: List[np.ndarray],
    landmarks_list: List[Optional[Dict[str, Dict[str, float]]]],
    elbow_angles: List[Optional[float]]
) -> None:
    """ã‚°ãƒ©ãƒ•ã‚¿ãƒ–ï¼šæ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•è¡¨ç¤º"""
    # è§£æç¨®é¡é¸æŠ
    analysis_types = {
        "è‚˜è§’åº¦": "right_elbow",
        "è‚©è§’åº¦": "right_shoulder",
        "è†è§’åº¦": "right_knee",
        "è…°è§’åº¦": "right_hip",
        "ä½“å¹¹å‚¾ã": "torso_axis",
        "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦": "shoulder_line",
        "éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦": "hip_line",
        "æ‰‹é¦–é€Ÿåº¦": "wrist_velocity",
    }
    
    selected_analysis_names = st.multiselect(
        "ğŸ“ˆ è¡¨ç¤ºã™ã‚‹ã‚°ãƒ©ãƒ•ã‚’é¸æŠ",
        options=list(analysis_types.keys()),
        default=["è‚˜è§’åº¦", "ä½“å¹¹å‚¾ã"],
        key="graph_analysis_select"
    )
    
    if not selected_analysis_names:
        st.info("è¡¨ç¤ºã™ã‚‹ã‚°ãƒ©ãƒ•ã‚’é¸æŠã—ã¦ãã ã•ã„")
        return
    
    # è§£æãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—
    analysis_data = {}
    
    # å„ç¨®è§’åº¦ã‚’è¨ˆç®—
    if any(name in ["è‚˜è§’åº¦", "è‚©è§’åº¦", "è†è§’åº¦", "è…°è§’åº¦", "ä½“å¹¹å‚¾ã", "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦", "éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦"] for name in selected_analysis_names):
        all_angles = calculate_all_angles_from_landmarks(landmarks_list)
        angle_mapping = {
            "è‚˜è§’åº¦": "right_elbow",
            "è‚©è§’åº¦": "right_shoulder",
            "è†è§’åº¦": "right_knee",
            "è…°è§’åº¦": "right_hip",
            "ä½“å¹¹å‚¾ã": "torso_axis",
            "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦": "shoulder_line",
            "éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦": "hip_line",
        }
        for name, key in angle_mapping.items():
            if name in selected_analysis_names:
                analysis_data[name] = all_angles[key]
    
    # æ‰‹é¦–é€Ÿåº¦ã‚’è¨ˆç®—
    if "æ‰‹é¦–é€Ÿåº¦" in selected_analysis_names:
        wrist_velocities = calculate_wrist_velocity(landmarks_list)
        analysis_data["æ‰‹é¦–é€Ÿåº¦"] = wrist_velocities
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤º
    if analysis_data:
        _render_multi_analysis_charts(analysis_data, selected_analysis_names)
    else:
        st.warning("è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")


def _render_video_tab(
    frames: List[np.ndarray],
    landmarks_list: List[Optional[Dict[str, Dict[str, float]]]],
    video_data: Dict[str, Any]
) -> None:
    """è§£æå‹•ç”»ã‚¿ãƒ–ï¼šéª¨æ ¼æç”»æ¸ˆã¿å‹•ç”»ã®ç”Ÿæˆã¨è¡¨ç¤º"""
    st.subheader("ğŸ¬ è§£æå‹•ç”»ç”Ÿæˆ")
    
    # è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰é¸æŠ
    display_mode_video = st.radio(
        "è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰",
        ["é€šå¸¸éª¨æ ¼", "æ®‹åƒãƒˆãƒ¬ã‚¤ãƒ«"],
        key="display_mode_video_radio_tab",
        horizontal=True
    )
    trail_mode = display_mode_video == "æ®‹åƒãƒˆãƒ¬ã‚¤ãƒ«"
    
    # æ®‹åƒãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼ˆæ®‹åƒãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
    max_trail_history = 20
    trail_decay = 0.92
    if trail_mode:
        max_trail_history = st.slider(
            "æ®‹åƒãƒ•ãƒ¬ãƒ¼ãƒ æ•°",
            min_value=5,
            max_value=30,
            value=20,
            key="trail_history_slider_tab"
        )
        trail_decay = st.slider(
            "æ®‹åƒã®æ¿ƒã•ï¼ˆå¤§ãã„ã»ã©æ¿ƒã„ï¼‰",
            min_value=0.85,
            max_value=0.98,
            value=0.92,
            step=0.01,
            key="trail_decay_slider_tab"
        )
    
    # å‹•ç”»ã‚¿ã‚¤ãƒ—é¸æŠãƒœã‚¿ãƒ³
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ¥ å…ƒå‹•ç”»+è§£æç·šã‚’ç”Ÿæˆ", key="generate_overlay_video_tab", use_container_width=True):
            with st.spinner("å…ƒå‹•ç”»ã«è§£æç·šã‚’é‡ã­ãŸå‹•ç”»ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."):
                overlay_video_path = create_annotated_video(
                    frames,
                    landmarks_list,
                    background_color=None,
                    trail_mode=trail_mode,
                    max_trail_history=max_trail_history,
                    trail_decay=trail_decay,
                )
                video_data["annotated_overlay_path"] = overlay_video_path
                if overlay_video_path and os.path.exists(overlay_video_path):
                    file_size = os.path.getsize(overlay_video_path)
                    st.success(f"âœ… ç”Ÿæˆå®Œäº†: {file_size / (1024*1024):.2f} MB")
                else:
                    st.error("âŒ å‹•ç”»ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    with col2:
        # èƒŒæ™¯è‰²é¸æŠ
        bg_color = st.radio("è§£æç·šã®ã¿å‹•ç”»ã®èƒŒæ™¯è‰²", ["é»’", "ç™½"], key="bg_color_radio_tab", horizontal=True)
        bg_color_value = "black" if bg_color == "é»’" else "white"
        
        if st.button("ğŸ¨ è§£æç·šã®ã¿ã‚’ç”Ÿæˆ", key="generate_skeleton_video_tab", use_container_width=True):
            with st.spinner(f"è§£æç·šã®ã¿ã®å‹•ç”»ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™ï¼ˆèƒŒæ™¯: {bg_color}ï¼‰..."):
                skeleton_video_path = create_annotated_video(
                    frames,
                    landmarks_list,
                    background_color=bg_color_value,
                    trail_mode=trail_mode,
                    max_trail_history=max_trail_history,
                    trail_decay=trail_decay,
                )
                video_data["annotated_skeleton_path"] = skeleton_video_path
                if skeleton_video_path and os.path.exists(skeleton_video_path):
                    file_size = os.path.getsize(skeleton_video_path)
                    st.success(f"âœ… ç”Ÿæˆå®Œäº†: {file_size / (1024*1024):.2f} MB")
                else:
                    st.error("âŒ å‹•ç”»ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # å‹•ç”»ã‚¿ã‚¤ãƒ—é¸æŠ
    video_options = []
    if video_data.get("annotated_overlay_path") and os.path.exists(video_data["annotated_overlay_path"]):
        video_options.append("å…ƒå‹•ç”»+è§£æç·š")
    if video_data.get("annotated_skeleton_path") and os.path.exists(video_data["annotated_skeleton_path"]):
        video_options.append("è§£æç·šã®ã¿")
    
    if video_options:
        selected_type = st.radio("è¡¨ç¤ºã™ã‚‹å‹•ç”»ã‚’é¸æŠ", video_options, key="video_type_radio_tab", horizontal=True)
        
        # é¸æŠã•ã‚ŒãŸå‹•ç”»ã®ãƒ‘ã‚¹ã‚’å–å¾—
        if selected_type == "å…ƒå‹•ç”»+è§£æç·š":
            current_video_path = video_data.get("annotated_overlay_path")
        else:
            current_video_path = video_data.get("annotated_skeleton_path")
        
        # å‹•ç”»è¡¨ç¤ºãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if current_video_path and os.path.exists(current_video_path):
            st.video(current_video_path)
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            with open(current_video_path, "rb") as video_file:
                video_bytes = video_file.read()
                st.download_button(
                    label="ğŸ“¥ å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=video_bytes,
                    file_name=f"pitching_analysis_{selected_type.replace('+', '_').replace(' ', '_')}.mp4",
                    mime="video/mp4",
                    key="download_video_button_tab",
                    use_container_width=True
                )
        else:
            st.warning("é¸æŠã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†åº¦ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
    else:
        st.info("ğŸ’¡ ä¸Šè¨˜ã®ãƒœã‚¿ãƒ³ã§å‹•ç”»ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")


def _render_evaluation_tab(
    frames: List[np.ndarray],
    landmarks_list: List[Optional[Dict[str, Dict[str, float]]]],
    elbow_angles: List[Optional[float]],
) -> None:
    """è©•ä¾¡ã‚¿ãƒ–ï¼šãƒ•ã‚©ãƒ¼ãƒ ã®è‡ªå‹•è©•ä¾¡ã‚’è¡¨ç¤º"""
    if not frames or not landmarks_list:
        st.info("è©•ä¾¡ã™ã‚‹å‹•ç”»ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    st.subheader("â­ ãƒ•ã‚©ãƒ¼ãƒ è©•ä¾¡")

    # è§£æã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—
    all_angles = calculate_all_angles_from_landmarks(landmarks_list)
    wrist_velocities = calculate_wrist_velocity(landmarks_list)
    metrics = compute_pitching_metrics(
        landmarks_list,
        elbow_angles,
        all_angles,
        wrist_velocities,
    )
    eval_result = evaluate_pitching_form(metrics)

    score = eval_result.get("score", 0)
    subscores = eval_result.get("subscores", {})
    comments = eval_result.get("comments", [])

    # ã‚¹ã‚³ã‚¢è¡¨ç¤º
    col1, col2 = st.columns([1, 2])
    with col1:
        st.metric("ç·åˆã‚¹ã‚³ã‚¢", f"{score} / 100")

    with col2:
        st.markdown("**ä»£è¡¨çš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹**")
        m = metrics
        st.write(
            {
                "æœ€å¤§è‚˜è§’åº¦": m.get("max_elbow_angle"),
                "ãƒªãƒªãƒ¼ã‚¹æ™‚è‚˜è§’åº¦": m.get("release_elbow_angle"),
                "ä½“å¹¹å‚¾ãï¼ˆãƒªãƒªãƒ¼ã‚¹æ™‚ï¼‰": m.get("torso_angle_at_release"),
                "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦ï¼ˆãƒªãƒªãƒ¼ã‚¹æ™‚ï¼‰": m.get("shoulder_angle_at_release"),
                "éª¨ç›¤è§’åº¦ï¼ˆãƒªãƒªãƒ¼ã‚¹æ™‚ï¼‰": m.get("hip_angle_at_release"),
                "ãƒªãƒªãƒ¼ã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ": m.get("release_frame"),
            }
        )

    st.markdown("---")

    # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼ˆã‚µãƒ–ã‚¹ã‚³ã‚¢ï¼‰
    if subscores:
        st.markdown("#### ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼ˆæŒ‡æ¨™åˆ¥ã‚¹ã‚³ã‚¢ï¼‰")
        labels = list(subscores.keys())
        values = [subscores[k] for k in labels]

        # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆç”¨ã«é–‰ã˜ã‚‹
        values.append(values[0])

        angles = np.linspace(0, 2 * np.pi, len(values), endpoint=True)

        fig, ax = plt.subplots(subplot_kw={"projection": "polar"})
        ax.plot(angles, values, "o-", linewidth=2)
        ax.fill(angles, values, alpha=0.25)
        ax.set_thetagrids(
            angles[:-1] * 180 / np.pi,
            labels,
            fontsize=10,
        )
        ax.set_ylim(0, 100)
        ax.set_title("ãƒ•ã‚©ãƒ¼ãƒ è©•ä¾¡ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ", pad=20)
        ax.grid(True)
        st.pyplot(fig)
    else:
        st.info("è©•ä¾¡ç”¨ã®ã‚µãƒ–ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    # ã‚³ãƒ¡ãƒ³ãƒˆè¡¨ç¤º
    st.markdown("#### ã‚³ãƒ¡ãƒ³ãƒˆ")
    for c in comments:
        st.markdown(f"- {c}")


def _render_video_detail_panel() -> None:
    """å³å´ãƒ‘ãƒãƒ«ï¼šé¸æŠå‹•ç”»ã®è©³ç´°è¡¨ç¤ºï¼ˆã‚¿ãƒ–æ§‹æˆï¼‰"""
    video_list = st.session_state.get("video_list", [])
    
    if not video_list:
        st.info("ğŸ“¤ å·¦å´ã‹ã‚‰å‹•ç”»ã‚’é¸æŠã™ã‚‹ã‹ã€æ–°ã—ã„å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„")
        return
    
    selected_idx = st.session_state.get("selected_video_index", 0)
    if selected_idx >= len(video_list):
        selected_idx = 0
        st.session_state["selected_video_index"] = 0
    
    video_data = video_list[selected_idx]
    frames = video_data.get("frames", [])
    landmarks_list = video_data.get("landmarks", [])
    elbow_angles = video_data.get("elbow_angles", [])
    
    # å‹•ç”»æƒ…å ±è¡¨ç¤º
    st.markdown(f"### ğŸ“¹ {video_data.get('name', 'å‹•ç”»')}")
    st.markdown(f"**ãƒ•ãƒ¬ãƒ¼ãƒ æ•°:** {len(frames)} | **è§£ææ¸ˆã¿:** âœ…")
    
    # ã‚¿ãƒ–æ§‹æˆ
    tabs = st.tabs(["ğŸ“Š è§£æçµæœ", "ğŸ“ˆ ã‚°ãƒ©ãƒ•", "ğŸ¬ è§£æå‹•ç”»", "â­ è©•ä¾¡"])
    
    with tabs[0]:
        _render_analysis_tab(frames, landmarks_list, elbow_angles)
    
    with tabs[1]:
        _render_graph_tab(frames, landmarks_list, elbow_angles)
    
    with tabs[2]:
        _render_video_tab(frames, landmarks_list, video_data)

    with tabs[3]:
        _render_evaluation_tab(frames, landmarks_list, elbow_angles)


def _render_analysis_results(
    frames: List[np.ndarray],
    landmarks_list: List[Optional[Dict[str, Dict[str, float]]]],
    elbow_angles: List[Optional[float]]
) -> None:
    """è§£æçµæœã‚’è¡¨ç¤ºã™ã‚‹
    
    Args:
        frames: ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒªã‚¹ãƒˆ
        landmarks_list: å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯è¾æ›¸ã®ãƒªã‚¹ãƒˆ
        elbow_angles: å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®è‚˜ã®è§’åº¦ã®ãƒªã‚¹ãƒˆ
    """
    st.subheader("è§£æçµæœ")
    
    # è§£æç¨®é¡é¸æŠ
    analysis_types = {
        "è‚˜è§’åº¦": "right_elbow",
        "è‚©è§’åº¦": "right_shoulder",
        "è†è§’åº¦": "right_knee",
        "è…°è§’åº¦": "right_hip",
        "ä½“å¹¹å‚¾ã": "torso_axis",
        "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦": "shoulder_line",
        "éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦": "hip_line",
        "æ‰‹é¦–é€Ÿåº¦": "wrist_velocity",
        "æŠ•çƒãƒ•ã‚§ãƒ¼ã‚º": "pitching_phases",
    }
    
    selected_analysis_names = st.multiselect(
        "è§£æç¨®é¡ã‚’é¸æŠ",
        options=list(analysis_types.keys()),
        default=["è‚˜è§’åº¦"],
        key="analysis_type_select"
    )
    
    # è§£æãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—
    analysis_data = {}
    phases = None
    phase_summary = None
    
    # å„ç¨®è§’åº¦ã‚’è¨ˆç®—
    if any(name in ["è‚˜è§’åº¦", "è‚©è§’åº¦", "è†è§’åº¦", "è…°è§’åº¦", "ä½“å¹¹å‚¾ã", "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦", "éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦"] for name in selected_analysis_names):
        all_angles = calculate_all_angles_from_landmarks(landmarks_list)
        angle_mapping = {
            "è‚˜è§’åº¦": "right_elbow",
            "è‚©è§’åº¦": "right_shoulder",
            "è†è§’åº¦": "right_knee",
            "è…°è§’åº¦": "right_hip",
            "ä½“å¹¹å‚¾ã": "torso_axis",
            "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦": "shoulder_line",
            "éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦": "hip_line",
        }
        for name, key in angle_mapping.items():
            if name in selected_analysis_names:
                analysis_data[name] = all_angles[key]
    
    # æ‰‹é¦–é€Ÿåº¦ã‚’è¨ˆç®—
    if "æ‰‹é¦–é€Ÿåº¦" in selected_analysis_names:
        wrist_velocities = calculate_wrist_velocity(landmarks_list)
        analysis_data["æ‰‹é¦–é€Ÿåº¦"] = wrist_velocities
    
    # æŠ•çƒãƒ•ã‚§ãƒ¼ã‚ºã‚’æ¨å®š
    if "æŠ•çƒãƒ•ã‚§ãƒ¼ã‚º" in selected_analysis_names:
        wrist_velocities = calculate_wrist_velocity(landmarks_list)
        phases = detect_pitching_phases(landmarks_list, elbow_angles, wrist_velocities)
        if phases:
            all_angles = calculate_all_angles_from_landmarks(landmarks_list)
            phase_summary = calculate_phase_summary(phases, all_angles, wrist_velocities)
    
    # è¡¨ç¤ºå½¢å¼é¸æŠ
    display_mode = st.radio(
        "è§£æçµæœã®è¡¨ç¤ºå½¢å¼",
        ["ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒä¸Šã«éª¨æ ¼æç”»", "è§£æç·šã®ã¿å‹•ç”»"],
        key="display_mode_radio"
    )
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ é¸æŠ
    frame_idx = st.slider(
        "ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é¸æŠ",
        min_value=0,
        max_value=len(frames) - 1,
        value=0
    )
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼è¡¨ç¤º
    if display_mode == "ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒä¸Šã«éª¨æ ¼æç”»":
        # ç¾åœ¨ãƒ•ãƒ¬ãƒ¼ãƒ ã®å„ç¨®è§’åº¦ã‚’å–å¾—
        torso_angle_val = None
        shoulder_line_angle_val = None
        hip_line_angle_val = None

        if "ä½“å¹¹å‚¾ã" in analysis_data:
            vals = analysis_data["ä½“å¹¹å‚¾ã"]
            if 0 <= frame_idx < len(vals):
                torso_angle_val = vals[frame_idx]

        if "è‚©ãƒ©ã‚¤ãƒ³è§’åº¦" in analysis_data:
            vals = analysis_data["è‚©ãƒ©ã‚¤ãƒ³è§’åº¦"]
            if 0 <= frame_idx < len(vals):
                shoulder_line_angle_val = vals[frame_idx]

        if "éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦" in analysis_data:
            vals = analysis_data["éª¨ç›¤ãƒ©ã‚¤ãƒ³è§’åº¦"]
            if 0 <= frame_idx < len(vals):
                hip_line_angle_val = vals[frame_idx]

        _render_frame_viewer(
            frames,
            frame_idx,
            landmarks_list[frame_idx],
            elbow_angles[frame_idx] if "è‚˜è§’åº¦" in selected_analysis_names else None,
            torso_angle=torso_angle_val,
            shoulder_line_angle=shoulder_line_angle_val,
            hip_line_angle=hip_line_angle_val,
        )
    
    # è¤‡æ•°è§£æçµæœã®ã‚°ãƒ©ãƒ•è¡¨ç¤º
    if analysis_data:
        _render_multi_analysis_charts(analysis_data, selected_analysis_names)
    
    # æŠ•çƒãƒ•ã‚§ãƒ¼ã‚ºã‚µãƒãƒªãƒ¼è¡¨ç¤º
    if phase_summary:
        _render_phase_summary(phase_summary)
    
    # éª¨æ ¼æç”»æ¸ˆã¿å‹•ç”»ã‚’ç”Ÿæˆãƒ»è¡¨ç¤º
    st.subheader("éª¨æ ¼æç”»æ¸ˆã¿å‹•ç”»")
    
    # è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰é¸æŠ
    display_mode_video = st.radio(
        "è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰",
        ["é€šå¸¸éª¨æ ¼", "æ®‹åƒãƒˆãƒ¬ã‚¤ãƒ«"],
        key="display_mode_video_radio",
        horizontal=True
    )
    trail_mode = display_mode_video == "æ®‹åƒãƒˆãƒ¬ã‚¤ãƒ«"
    
    # æ®‹åƒãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼ˆæ®‹åƒãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
    max_trail_history = 20
    trail_decay = 0.92
    if trail_mode:
        max_trail_history = st.slider(
            "æ®‹åƒãƒ•ãƒ¬ãƒ¼ãƒ æ•°",
            min_value=5,
            max_value=30,
            value=20,
            key="trail_history_slider"
        )
        trail_decay = st.slider(
            "æ®‹åƒã®æ¿ƒã•ï¼ˆå¤§ãã„ã»ã©æ¿ƒã„ï¼‰",
            min_value=0.85,
            max_value=0.98,
            value=0.92,
            step=0.01,
            key="trail_decay_slider"
        )
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    video_overlay_key = "annotated_video_overlay_path"  # å…ƒå‹•ç”»+è§£æç·š
    video_skeleton_key = "annotated_video_skeleton_path"  # è§£æç·šã®ã¿
    selected_video_type_key = "selected_video_type"  # é¸æŠä¸­ã®å‹•ç”»ã‚¿ã‚¤ãƒ—
    show_video_key = "show_annotated_video"
    
    if show_video_key not in st.session_state:
        st.session_state[show_video_key] = False
    if selected_video_type_key not in st.session_state:
        st.session_state[selected_video_type_key] = "overlay"
    
    # å‹•ç”»ã‚¿ã‚¤ãƒ—é¸æŠãƒœã‚¿ãƒ³
    col1, col2 = st.columns(2)
    with col1:
        if st.button("å…ƒå‹•ç”»+è§£æç·šã‚’ç”Ÿæˆ", key="generate_overlay_video"):
            with st.spinner("å…ƒå‹•ç”»ã«è§£æç·šã‚’é‡ã­ãŸå‹•ç”»ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."):
                overlay_video_path = create_annotated_video(
                    frames,
                    landmarks_list,
                    background_color=None,
                    trail_mode=trail_mode,
                    max_trail_history=max_trail_history,
                    trail_decay=trail_decay,
                )
                st.session_state[video_overlay_key] = overlay_video_path
                if overlay_video_path and os.path.exists(overlay_video_path):
                    file_size = os.path.getsize(overlay_video_path)
                    st.success(f"ç”Ÿæˆå®Œäº†: {file_size / (1024*1024):.2f} MB")
                else:
                    st.error("å‹•ç”»ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    with col2:
        # èƒŒæ™¯è‰²é¸æŠ
        bg_color = st.radio("è§£æç·šã®ã¿å‹•ç”»ã®èƒŒæ™¯è‰²", ["é»’", "ç™½"], key="bg_color_radio", horizontal=True)
        bg_color_value = "black" if bg_color == "é»’" else "white"
        
        if st.button("è§£æç·šã®ã¿ã‚’ç”Ÿæˆ", key="generate_skeleton_video"):
            with st.spinner(f"è§£æç·šã®ã¿ã®å‹•ç”»ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™ï¼ˆèƒŒæ™¯: {bg_color}ï¼‰..."):
                skeleton_video_path = create_annotated_video(
                    frames,
                    landmarks_list,
                    background_color=bg_color_value,
                    trail_mode=trail_mode,
                    max_trail_history=max_trail_history,
                    trail_decay=trail_decay,
                )
                st.session_state[video_skeleton_key] = skeleton_video_path
                if skeleton_video_path and os.path.exists(skeleton_video_path):
                    file_size = os.path.getsize(skeleton_video_path)
                    st.success(f"ç”Ÿæˆå®Œäº†: {file_size / (1024*1024):.2f} MB")
                else:
                    st.error("å‹•ç”»ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # å‹•ç”»ã‚¿ã‚¤ãƒ—é¸æŠ
    video_options = []
    if st.session_state.get(video_overlay_key) and os.path.exists(st.session_state[video_overlay_key]):
        video_options.append("å…ƒå‹•ç”»+è§£æç·š")
    if st.session_state.get(video_skeleton_key) and os.path.exists(st.session_state[video_skeleton_key]):
        video_options.append("è§£æç·šã®ã¿")
    
    if video_options:
        selected_type = st.radio("è¡¨ç¤ºã™ã‚‹å‹•ç”»ã‚’é¸æŠ", video_options, key="video_type_radio")
        st.session_state[selected_video_type_key] = "overlay" if selected_type == "å…ƒå‹•ç”»+è§£æç·š" else "skeleton"
        
        # é¸æŠã•ã‚ŒãŸå‹•ç”»ã®ãƒ‘ã‚¹ã‚’å–å¾—
        if st.session_state[selected_video_type_key] == "overlay":
            current_video_path = st.session_state.get(video_overlay_key)
        else:
            current_video_path = st.session_state.get(video_skeleton_key)
        
        # å‹•ç”»è¡¨ç¤ºãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        if current_video_path and os.path.exists(current_video_path):
            col1, col2, col3 = st.columns([1, 1, 2])
            with col1:
                if st.button("å‹•ç”»ã‚’è¡¨ç¤º", key="show_video_button"):
                    st.session_state[show_video_key] = True
                    st.rerun()
            
            with col2:
                if st.button("å‹•ç”»ã‚’éè¡¨ç¤º", key="hide_video_button"):
                    st.session_state[show_video_key] = False
                    st.rerun()
            
            with col3:
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                with open(current_video_path, "rb") as video_file:
                    video_bytes = video_file.read()
                    st.download_button(
                        label="ğŸ“¥ å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=video_bytes,
                        file_name=f"pitching_analysis_{selected_type.replace('+', '_').replace(' ', '_')}.mp4",
                        mime="video/mp4",
                        key="download_video_button"
                    )
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«åŸºã¥ã„ã¦å‹•ç”»ã‚’è¡¨ç¤º
            if st.session_state[show_video_key]:
                st.video(current_video_path)
                st.info(f"å‹•ç”»ã‚’å†ç”Ÿä¸­: {current_video_path}")
    else:
        st.info("ä¸Šè¨˜ã®ãƒœã‚¿ãƒ³ã§å‹•ç”»ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")



def _process_video_analysis(
    uploaded_file: Any,
    progress_container: Any = None
) -> Tuple[
    Optional[List[np.ndarray]],
    Optional[List[Optional[Dict[str, Dict[str, float]]]]],
    Optional[List[Optional[float]]]
]:
    """å‹•ç”»è§£æã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆCloud Run å¯¾å¿œï¼šé€²è¡ŒçŠ¶æ³è¡¨ç¤ºï¼‰
    
    Args:
        uploaded_file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        progress_container: é€²è¡ŒçŠ¶æ³è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
    
    Returns:
        (ãƒ•ãƒ¬ãƒ¼ãƒ ãƒªã‚¹ãƒˆ, ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒªã‚¹ãƒˆ, è§’åº¦ãƒªã‚¹ãƒˆ)ã®ã‚¿ãƒ—ãƒ«
    """
    if progress_container:
        progress_container.info("ğŸ“¹ å‹•ç”»ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    
    frames = load_video_frames(uploaded_file, progress_container=progress_container)
    
    if frames is None or len(frames) == 0:
        if progress_container:
            progress_container.error("âŒ å‹•ç”»ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return None, None, None
    
    if progress_container:
        progress_container.info("ğŸ¤– å§¿å‹¢æ¨å®šã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™...")
    
    landmarks_list = process_video_frames(frames, progress_container=progress_container)
    
    if progress_container:
        progress_container.info("ğŸ“ è§’åº¦ã‚’è¨ˆç®—ã—ã¦ã„ã¾ã™...")
    
    elbow_angles = calculate_elbow_angles_from_landmarks(landmarks_list)
    
    if progress_container:
        progress_container.success(f"âœ… è§£æå®Œäº†ï¼{len(frames)} ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è§£æã—ã¾ã—ãŸ")
    
    return frames, landmarks_list, elbow_angles


def main() -> None:
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆCloud Run å¯¾å¿œï¼šè§£æä¸­ã«ç”»é¢ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œãªã„ï¼‰"""
    st.title("âš¾ é‡çƒãƒ•ã‚©ãƒ¼ãƒ è§£æã‚¢ãƒ—ãƒª")
    st.markdown("---")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "analysis_results" not in st.session_state:
        st.session_state["analysis_results"] = []
    if "current_analysis_index" not in st.session_state:
        st.session_state["current_analysis_index"] = -1
    if "is_analyzing" not in st.session_state:
        st.session_state["is_analyzing"] = False
    if "uploaded_file_name" not in st.session_state:
        st.session_state["uploaded_file_name"] = None
    if "uploaded_file_bytes" not in st.session_state:
        st.session_state["uploaded_file_bytes"] = None
    
    # å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ“¤ å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # è§£æä¸­ã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–
    uploaded_file = None
    if not st.session_state["is_analyzing"]:
        uploaded_file = _render_video_upload()
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
    if uploaded_file is not None:
        uploaded_file.seek(0)
        st.session_state["uploaded_file_name"] = uploaded_file.name
        st.session_state["uploaded_file_bytes"] = uploaded_file.read()
        uploaded_file.seek(0)  # èª­ã¿å–ã‚Šä½ç½®ã‚’ãƒªã‚»ãƒƒãƒˆ
    
    # è§£æä¸­ã§ãªã„å ´åˆã®ã¿è§£æãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    if not st.session_state["is_analyzing"]:
        if st.session_state["uploaded_file_name"] is not None:
            col1, col2 = st.columns([1, 4])
            with col1:
                analyze_button = st.button("ğŸš€ è§£æã‚’é–‹å§‹", type="primary", use_container_width=True)
            
            with col2:
                st.info(f"ğŸ“ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {st.session_state['uploaded_file_name']}")
            
            if analyze_button:
                # è§£æçŠ¶æ…‹ã‚’é–‹å§‹
                st.session_state["is_analyzing"] = True
                st.rerun()
    
    # è§£æä¸­ã®å‡¦ç†
    if st.session_state["is_analyzing"]:
        # è§£æä¸­è¡¨ç¤º
        st.markdown("---")
        progress_section = st.container()
        
        with progress_section:
            st.subheader("ğŸ”„ è§£æä¸­...")
            st.info("â³ å‹•ç”»ã®è§£æã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚")
            st.warning("âš ï¸ è§£æä¸­ã¯ã“ã®ãƒšãƒ¼ã‚¸ã‚’é–‰ã˜ãªã„ã§ãã ã•ã„ã€‚")
            
            # é€²è¡ŒçŠ¶æ³è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
            progress_container = st.container()
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†æ§‹ç¯‰
            if st.session_state["uploaded_file_bytes"] is not None:
                # BytesIO ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
                uploaded_file_obj = io.BytesIO(st.session_state["uploaded_file_bytes"])
                uploaded_file_obj.name = st.session_state["uploaded_file_name"]
                
                try:
                    # è§£æã‚’å®Ÿè¡Œï¼ˆé•·æ™‚é–“å‡¦ç†ã®ãŸã‚ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ ï¼‰
                    with progress_container:
                        frames, landmarks_list, elbow_angles = _process_video_analysis(
                            uploaded_file_obj,
                            progress_container=progress_container
                        )
                    
                    # è§£æå®Œäº†å¾Œã®å‡¦ç†
                    if frames is not None and landmarks_list is not None and elbow_angles is not None:
                        # è§£æçµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                        analysis_data = {
                            "name": st.session_state["uploaded_file_name"],
                            "frames": frames,
                            "landmarks": landmarks_list,
                            "elbow_angles": elbow_angles,
                            "annotated_overlay_path": None,
                            "annotated_skeleton_path": None,
                        }
                        st.session_state["analysis_results"].append(analysis_data)
                        st.session_state["current_analysis_index"] = len(st.session_state["analysis_results"]) - 1
                        
                        # è§£æçŠ¶æ…‹ã‚’çµ‚äº†
                        st.session_state["is_analyzing"] = False
                        
                        # è§£æå®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                        st.success("âœ… è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼çµæœã¯ä¸‹ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
                        
                        # ç”»é¢ã‚’æ›´æ–°ï¼ˆè§£æå®Œäº†å¾Œã®ã¿ï¼‰
                        st.rerun()
                    else:
                        # è§£æå¤±æ•—
                        st.session_state["is_analyzing"] = False
                        st.error("âŒ è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                        st.rerun()
                except Exception as e:
                    # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼
                    st.session_state["is_analyzing"] = False
                    st.error(f"âŒ è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    st.rerun()
            else:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
                st.session_state["is_analyzing"] = False
                st.error("âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                st.rerun()
    
    st.markdown("---")
    
    # è§£æçµæœã‚’ç”»é¢ä¸‹ã«è¿½åŠ è¡¨ç¤ºï¼ˆç”»é¢é·ç§»ãªã—ï¼‰
    if st.session_state["analysis_results"]:
        st.subheader("ğŸ“Š è§£æçµæœ")
        
        # è§£æçµæœã®é¸æŠï¼ˆè¤‡æ•°ã®è§£æçµæœãŒã‚ã‚‹å ´åˆï¼‰
        if len(st.session_state["analysis_results"]) > 1:
            result_names = [f"{i+1}. {result['name']}" for i, result in enumerate(st.session_state["analysis_results"])]
            selected_idx = st.selectbox(
                "è¡¨ç¤ºã™ã‚‹è§£æçµæœã‚’é¸æŠ",
                options=range(len(result_names)),
                format_func=lambda x: result_names[x],
                index=st.session_state["current_analysis_index"] if st.session_state["current_analysis_index"] >= 0 else 0
            )
            st.session_state["current_analysis_index"] = selected_idx
        else:
            st.session_state["current_analysis_index"] = 0
        
        # ç¾åœ¨ã®è§£æçµæœã‚’å–å¾—
        if st.session_state["current_analysis_index"] >= 0:
            current_result = st.session_state["analysis_results"][st.session_state["current_analysis_index"]]
            frames = current_result["frames"]
            landmarks_list = current_result["landmarks"]
            elbow_angles = current_result["elbow_angles"]
            
            # è§£æçµæœã‚’è¡¨ç¤ºï¼ˆã‚¿ãƒ–å½¢å¼ï¼‰
            tabs = st.tabs(["ğŸ“Š è§£æçµæœ", "ğŸ“ˆ ã‚°ãƒ©ãƒ•", "ğŸ¬ è§£æå‹•ç”»", "â­ è©•ä¾¡"])
            
            with tabs[0]:
                _render_analysis_tab(frames, landmarks_list, elbow_angles)
            
            with tabs[1]:
                _render_graph_tab(frames, landmarks_list, elbow_angles)
            
            with tabs[2]:
                _render_video_tab(frames, landmarks_list, current_result)
            
            with tabs[3]:
                _render_evaluation_tab(frames, landmarks_list, elbow_angles)
    elif not st.session_state["is_analyzing"]:
        st.info("ğŸ’¡ å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„")


if __name__ == "__main__":
    main()

